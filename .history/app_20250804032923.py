import streamlit as st
import pandas as pd
import joblib
import matplotlib.pyplot as plt
from wordcloud import WordCloud
from sklearn.feature_extraction.text import TfidfVectorizer
import re
import nltk
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer

# T√©l√©chargements NLTK (√† faire une fois)
nltk.download('stopwords')

# Pr√©traitement du texte (doit correspondre √† celui utilis√© dans l'entra√Ænement)
stop_words = set(stopwords.words('english'))
stemmer = PorterStemmer()

def preprocess_text(text):
    import string
    import re
    if not isinstance(text, str):
        return ""

    text = text.lower()
    text = re.sub(r'<.*?>', '', text)
    text = text.translate(str.maketrans('', '', string.punctuation))
    words = text.split()
    words = [w for w in words if w not in stop_words]
    words = [stemmer.stem(w) for w in words]
    return ' '.join(words)


# Charger les donn√©es pour EDA
import os

@st.cache_data
def load_data():
    path = os.path.join(os.path.dirname(__file__), "DataSet_Emails.csv")
    return pd.read_csv(path)


df = load_data()

# Pr√©traitement des textes si pas d√©j√† faits
if 'clean_text' not in df.columns:
    df['text'] = df['text'].fillna('')
    df['clean_text'] = df['text'].apply(preprocess_text)

# Charger le mod√®le entra√Æn√© et le vectorizer
model = joblib.load("best_model.pkl")
  # Doit matcher avec entra√Ænement

# üé® Interface Streamlit
st.title("üìß D√©tecteur de Spam - BMSecurity AI")

# üìä Onglets : Analyse / Pr√©diction
tabs = st.tabs(["üîç Analyse Exploratoire", "ü§ñ D√©tection Spam"])

# --- üß™ Onglet EDA ---
with tabs[0]:
    st.header("Exploration du Dataset")
    st.write("**R√©partition des classes (Ham vs Spam)**")
    st.bar_chart(df['label_text'].value_counts())

    # WordCloud Ham & Spam
    spam_words = ' '.join(df[df['label_text'] == 'spam']['clean_text'])
    ham_words = ' '.join(df[df['label_text'] == 'ham']['clean_text'])

    st.write("**Nuage de mots - Spam**")
    wc_spam = WordCloud(width=800, height=400).generate(spam_words)
    st.image(wc_spam.to_array(), use_column_width=True)

    st.write("**Nuage de mots - Ham**")
    wc_ham = WordCloud(width=800, height=400).generate(ham_words)
    st.image(wc_ham.to_array(), use_column_width=True)

# --- üß† Onglet D√©tection Spam ---
with tabs[1]:
    st.header("Testez un Email")
    user_input = st.text_area("‚úçÔ∏è Entrez le contenu de l'email :", height=200)

    if st.button("Analyser"):
        if user_input.strip() == "":
            st.warning("Veuillez saisir un texte √† analyser.")
        else:
            clean_input = preprocess_text(user_input)
            input_vector = vectorizer.transform([clean_input])
            prediction = model.predict(input_vector)[0]
            proba = model.predict_proba(input_vector)[0]

            if prediction == 1:
                st.error(f"üö® L'email est probablement un **SPAM**.")
            else:
                st.success(f"‚úÖ L'email est probablement **l√©gitime (HAM)**.")

            st.write(f"**Probabilit√© Spam : {proba[1]*100:.2f}%**")
            st.write(f"**Probabilit√© Ham : {proba[0]*100:.2f}%**")

model_path = os.path.join(os.path.dirname(__file__), "best_model.pkl")

if not os.path.exists(model_path):
    st.error("‚ùå Fichier 'best_model.pkl' introuvable. Veuillez l'entra√Æner et le sauvegarder.")
    st.stop()

model = joblib.load(model_path)